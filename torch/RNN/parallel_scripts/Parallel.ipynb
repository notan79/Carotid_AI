{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ed6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from AutoEncoderCNN import AE_CNN\n",
    "from GridSearch import GridSearch\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876b49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e65cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "0.18.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0730a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Computer Name is:r5u11n1.puma.hpc.arizona.edu\n",
      "Your Computer IP Address is:10.141.18.21\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "IPAddr = socket.gethostbyname(hostname)\n",
    "\n",
    "print(\"Your Computer Name is:\" + hostname)\n",
    "print(\"Your Computer IP Address is:\" + IPAddr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae3146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_data, optimizer, loss_function, gpu_id, verbose = 2):\n",
    "            \n",
    "        self.gpu_id = gpu_id\n",
    "        self.model = model.to(gpu_id)\n",
    "        self.train_data = train_data\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_function\n",
    "        print('here1')\n",
    "        self.model = DDP(model, device_ids=[gpu_id])\n",
    "        print('here2')\n",
    "\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        self.model.share_memory()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def trainAE(EPOCHS):\n",
    "            \n",
    "        loss_arr = []\n",
    "        min_loss = None\n",
    "        outputs = []\n",
    "        early_stop = False\n",
    "        early_stop_depth = self._early_stop_depth\n",
    "        \n",
    "        loader = self.train_data.to(self.gpu_id)\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            \n",
    "            self.train_data.sampler.set_epoch(epoch) # allows shuffling to work properly\n",
    "            \n",
    "            if early_stop:\n",
    "                if self._verbose != 0:\n",
    "                    print(f'\\n\\n------EARLY STOP {min_loss}------\\n\\n')\n",
    "                break\n",
    "\n",
    "            count = 0\n",
    "\n",
    "            model.train()\n",
    "            for (image, _) in loader:\n",
    "                image = image.to(self.gpu_id)\n",
    "                #image = image.flatten(start_dim=1) # ignore the batch_size\n",
    "\n",
    "                recon = model(image)\n",
    "                loss = loss_function(recon, image)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                \n",
    "                # UI\n",
    "                if self._verbose == 2:\n",
    "                    sys.stdout.write('\\r')\n",
    "                    sys.stdout.write(\"Epoch: {} [{:{}}] {:.1f}% | Loss: {}\".format(epoch+1, \"=\"*count, \n",
    "                                                                               len(loader)-1, \n",
    "                                                                               (100/(len(loader)-1)*count), \n",
    "                                                                               loss.item()))\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                count += 1\n",
    "                \n",
    "            loss_arr.append(loss.item())\n",
    "            if not min_loss:\n",
    "                min_loss = loss_arr[0]\n",
    "            if early_stop_depth >= 1 and early_stop_depth < len(loss_arr[loss_arr.index(min_loss):]):\n",
    "                early_stop = True\n",
    "                for loss_item in loss_arr[loss_arr.index(min_loss):]:\n",
    "                    if loss_item < min_loss:\n",
    "                        min_loss = loss_item\n",
    "                        early_stop = False\n",
    "               \n",
    "                    \n",
    "            outputs.append((epoch, image[1], recon[1]))\n",
    "            \n",
    "            if self._verbose != 0:\n",
    "                print(f'\\nEpoch: {epoch + 1} | Loss: {loss.item():.4f}', end='\\n'*2)\n",
    "                \n",
    "        torch.save(self.model.module.state_dict(), f'./models/Parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c37c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(BATCH_SIZE):\n",
    "    PATH = '/groups/francescavitali/eb2/subImages_slide299/H&E' # has 506 images\n",
    "\n",
    "    tensor_transform = transforms.ToTensor()\n",
    "\n",
    "    dataset = datasets.ImageFolder(PATH, \n",
    "                                  transform = tensor_transform) #loads the images\n",
    "\n",
    "    train_set, val_set, test_set = torch.utils.data.random_split(dataset,\n",
    "                                                       [404,51,51],# 70%, 30%\n",
    "                                                       generator=torch.Generator(device='cpu'))\n",
    "\n",
    "    train = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                        batch_size = BATCH_SIZE,\n",
    "                                        shuffle = False,\n",
    "                                        sampler= DistributedSampler(train_set)) # copy paste for val and test\n",
    "    \n",
    "    \n",
    "    return (train)\n",
    "    \n",
    "    \n",
    "def ddp_setup(rank, world_size):\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"65531\" # some random port\n",
    "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "    \n",
    "def x(rank, world_size, EPOCHS=10, BATCH_SIZE=4, LR = 0.0001, WD = 1e-5):\n",
    "    ddp_setup(rank, world_size)\n",
    "    loader = get_loaders(BATCH_SIZE)\n",
    "    model = AE_CNN()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay = WD)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "\n",
    "    print(2)\n",
    "\n",
    "    trainer = Trainer(model, loader, optimizer, loss_function, rank, verbose=2)\n",
    "    print(3)\n",
    "    trainer.trainAE(EPOCHS)\n",
    "    print(4)\n",
    "    destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6035f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 1\n",
    "LR = 0.0001\n",
    "WD = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92dd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(world_size):\n",
    "    torch.cuda.set_device(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3eec87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'x' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43mWD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:281\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    275\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:237\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:177\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    171\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    179\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    180\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    181\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    182\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_files[error_index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    185\u001b[0m     original_trace \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fh)\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mp.spawn(x, args=(world_size, EPOCHS, BATCH_SIZE,LR,WD))\n",
    "#     # NOTE: this is required for the ``fork`` method to work\n",
    "#     model.share_memory()\n",
    "#     processes = []\n",
    "#     for rank in range(num_processes):\n",
    "#         p = mp.Process(target=train, args=(model,))\n",
    "#         p.start()\n",
    "#         processes.append(p)\n",
    "#     for p in processes:\n",
    "#         p.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037e7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
