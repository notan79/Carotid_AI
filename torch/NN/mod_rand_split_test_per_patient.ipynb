{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6feb43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from AutoEncoderCNN import AE_CNN\n",
    "from util.random_patient import random_split\n",
    "from util.ImageFolderWithPaths import ImageFolderWithPaths\n",
    "from util.loader_info import get_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b710ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "torch.set_default_device(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc38aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting labels\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "Returning\n"
     ]
    }
   ],
   "source": [
    "MAIN_PATH = '/home/u6/njcrutchfield/torch/NN/pill_data/pillQC-main/' # images are 225 x 225 x 3\n",
    "\n",
    "PATH1 = '/groups/francescavitali/eb2/NewsubSubImages4/H&E/'\n",
    "PATH2 = '/groups/francescavitali/eb2/NewsubSubImages4/H&E/S'\n",
    "\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "dataset = ImageFolderWithPaths(MAIN_PATH, transform = tensor_transform)\n",
    "\n",
    "SPLIT = [0.8, 0.1, 0.1]\n",
    "\n",
    "train_set, val_set, test_set = random_split(PATH1, PATH2, dataset, split_percent = SPLIT, rand_seed = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4fd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                            batch_size = 4,\n",
    "                                            shuffle = True,\n",
    "                                            generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d436517",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset = test_set,\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = True,\n",
    "                                            generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6feaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1643, 1: 4988}\n"
     ]
    }
   ],
   "source": [
    "print(get_totals(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd60b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE_CNN().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('./models/model_gs.pth')) # loading best model state\n",
    "\n",
    "# setting the encoder\n",
    "encoder = model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82e6a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(64, 32, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): Conv2d(32, 26, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=28314, out_features=28314, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db4d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._feed_forward = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28314, 16384),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16384, 4096),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4096, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "        self._sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    \n",
    "    def forward(self,  x):\n",
    "        output = self._feed_forward(x) \n",
    "        return self._sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecc0093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNet().to(device)\n",
    "nn.load_state_dict(torch.load('./ClassifierModels/big_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f9d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u6/njcrutchfield/.local/lib/python3.8/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 28.35%\n"
     ]
    }
   ],
   "source": [
    "ans = []\n",
    "total_samples = 0\n",
    "total_correct = 0\n",
    "nn.to(device)\n",
    "nn.eval()\n",
    "for (image, label, fname) in test_loader:\n",
    "    nn.eval()\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # feeding through nn\n",
    "        encoded = encoder(image)\n",
    "        not_rounded = nn._feed_forward(encoded)\n",
    "        outputs = nn._sigmoid(not_rounded)\n",
    "        \n",
    "        # results based on sigmoid\n",
    "        if outputs < 0.5: \n",
    "            outputs = 0\n",
    "        else:\n",
    "            outputs = 1\n",
    "            \n",
    "        # for calculating percentage and visualizing\n",
    "        total_correct += (outputs == label).item()\n",
    "        ans.append((label.item(), outputs, fname))\n",
    "\n",
    "        \n",
    "print(f'Accuracy: {total_correct/len(test_loader)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "928b7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {} # d[patient #] = [goal, # of 1's guessed, total images] \n",
    "for i in range(len(ans)):\n",
    "    patient = ans[i][2][0].split('/')[7]\n",
    "    if patient in d:\n",
    "        d[patient][1] += ans[i][1]\n",
    "        d[patient][2] += 1\n",
    "    else:\n",
    "        d[patient] = [ans[i][0], ans[i][1], 1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c198d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with thresh=1: 62.50%\n",
      "Accuracy with thresh=2: 62.50%\n",
      "Accuracy with thresh=3: 62.50%\n",
      "Accuracy with thresh=4: 62.50%\n",
      "Accuracy with thresh=5: 62.50%\n",
      "Accuracy with thresh=6: 50.00%\n",
      "Accuracy with thresh=7: 50.00%\n",
      "Accuracy with thresh=8: 50.00%\n",
      "Accuracy with thresh=9: 50.00%\n",
      "Accuracy with thresh=10: 50.00%\n",
      "Accuracy with thresh=11: 50.00%\n",
      "Accuracy with thresh=12: 50.00%\n",
      "Accuracy with thresh=13: 50.00%\n",
      "Accuracy with thresh=14: 50.00%\n",
      "Accuracy with thresh=15: 62.50%\n",
      "Accuracy with thresh=16: 62.50%\n",
      "Accuracy with thresh=17: 62.50%\n",
      "Accuracy with thresh=18: 62.50%\n",
      "Accuracy with thresh=19: 62.50%\n",
      "Accuracy with thresh=20: 62.50%\n",
      "Accuracy with thresh=21: 62.50%\n",
      "Accuracy with thresh=22: 62.50%\n",
      "Accuracy with thresh=23: 62.50%\n",
      "Accuracy with thresh=24: 62.50%\n",
      "Accuracy with thresh=25: 62.50%\n",
      "Accuracy with thresh=26: 62.50%\n",
      "Accuracy with thresh=27: 62.50%\n",
      "Accuracy with thresh=28: 62.50%\n",
      "Accuracy with thresh=29: 62.50%\n",
      "Accuracy with thresh=30: 62.50%\n",
      "Accuracy with thresh=31: 75.00%\n",
      "Accuracy with thresh=32: 75.00%\n",
      "Accuracy with thresh=33: 75.00%\n",
      "Accuracy with thresh=34: 75.00%\n",
      "Accuracy with thresh=35: 62.50%\n",
      "Accuracy with thresh=36: 62.50%\n",
      "Accuracy with thresh=37: 75.00%\n",
      "Accuracy with thresh=38: 75.00%\n",
      "Accuracy with thresh=39: 75.00%\n",
      "Accuracy with thresh=40: 75.00%\n",
      "Accuracy with thresh=41: 75.00%\n",
      "Accuracy with thresh=42: 75.00%\n",
      "Accuracy with thresh=43: 75.00%\n",
      "Accuracy with thresh=44: 75.00%\n",
      "Accuracy with thresh=45: 75.00%\n",
      "Accuracy with thresh=46: 75.00%\n",
      "Accuracy with thresh=47: 75.00%\n",
      "Accuracy with thresh=48: 75.00%\n",
      "Accuracy with thresh=49: 75.00%\n",
      "Accuracy with thresh=50: 62.50%\n",
      "Accuracy with thresh=51: 62.50%\n",
      "Accuracy with thresh=52: 62.50%\n",
      "Accuracy with thresh=53: 62.50%\n",
      "Accuracy with thresh=54: 62.50%\n"
     ]
    }
   ],
   "source": [
    "max_thresh = 55\n",
    "for thresh in range(1,max_thresh):\n",
    "    correct = 0\n",
    "    for patient, val in d.items():\n",
    "        guess = 0\n",
    "        if val[1] > thresh:\n",
    "            guess = 1\n",
    "        if guess == val[0]:\n",
    "            correct += 1\n",
    "    print(f'Accuracy with {thresh=}: {correct/len(d.keys())*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc5a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
