{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a013e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from AutoEncoderCNN import AE_CNN\n",
    "from GridSearch import GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a2eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89fe42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb97273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/groups/francescavitali/eb2/NewsubSubImages4/H&E' # /groups/francescavitali/eb2/subImages_slide299/H&E\n",
    "BATCH_SIZE = 4 \n",
    "SPLIT = [55767, 6971, 6971]\n",
    "\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "dataset = datasets.ImageFolder(PATH, \n",
    "                               transform = tensor_transform) #loads the images\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset,\n",
    "                                                           SPLIT,# 80%, 10%, 10%\n",
    "                                                           generator=torch.Generator(device=device))\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset = train_set,\n",
    "                                            batch_size = BATCH_SIZE,\n",
    "                                            shuffle = True,\n",
    "                                            generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ecbc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69709"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16cf6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE_CNN().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('./models/model_gs.pth')) # loading best model state\n",
    "#model.load_state_dict(torch.load('./models/Copy Models/model_gs_3-28-2024.pth'))\n",
    "\n",
    "# setting the encoder and decoder for visualization\n",
    "encoder = model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5fe0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img Shape: torch.Size([4, 3, 299, 299])\n",
      "Encoded Shape: torch.Size([4, 28314])\n",
      "Flattened: torch.Size([4, 28314])\n",
      "Goal: tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u6/njcrutchfield/.local/lib/python3.8/site-packages/torch/utils/_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for(img, goal) in loader: # goal will be a tensor of len == batch_size\n",
    "        if count == 1:\n",
    "            break\n",
    "        img = img.to(device)\n",
    "        print(f'Img Shape: {img.shape}')\n",
    "        encoded_img = encoder(img)\n",
    "        print(f'Encoded Shape: {encoded_img.shape}')\n",
    "        flattened = encoded_img.flatten(start_dim = 1)\n",
    "        print(f'Flattened: {flattened.shape}')\n",
    "        print(f'Goal: {goal.unsqueeze(1)}')\n",
    "        print()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c20654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(64, 32, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): Conv2d(32, 26, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=28314, out_features=28314, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a36303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._feed_forward = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28314, 16384),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16384, 4096),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4096, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1),\n",
    "        )\n",
    "        self._sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    \n",
    "    def forward(self,  x):\n",
    "        output = self._feed_forward(flattened)\n",
    "        return self._sigmoid(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ca5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849985bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0000001 \n",
    "weight_decay = 1e-5\n",
    "EPOCHS = 30\n",
    "\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06eaa0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset = val_set,\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = True,\n",
    "                                            generator=torch.Generator(device=device))\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set,\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = True,\n",
    "                                            generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59bbac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loader P(1): 0.38975756706354897\n",
      "Test loader P(1): 0.3854540238129393\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for (image_val, label_val) in val_loader:\n",
    "    if(label_val == 1):\n",
    "        c += 1\n",
    "print(f'Val loader P(1): {c/len(val_loader)}')\n",
    "\n",
    "c = 0\n",
    "for (image_test, label_test) in test_loader:\n",
    "    if(label_test == 1):\n",
    "        c += 1\n",
    "print(f'Test loader P(1): {c/len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 | Loss: 0.0000 | Val Accuracy: 60.45%\n",
      "\n",
      "\n",
      "Epoch: 2 | Loss: 0.0000 | Val Accuracy: 60.55%\n",
      "\n",
      "\n",
      "Epoch: 3 | Loss: 0.0000 | Val Accuracy: 60.59%\n",
      "\n",
      "\n",
      "Epoch: 4 | Loss: 0.0000 | Val Accuracy: 60.61%\n",
      "\n",
      "\n",
      "Epoch: 5 | Loss: 0.0000 | Val Accuracy: 60.59%\n",
      "\n",
      "\n",
      "Epoch: 6 | Loss: 0.0000 | Val Accuracy: 60.65%\n",
      "\n",
      "\n",
      "Epoch: 7 | Loss: 0.0000 | Val Accuracy: 60.65%\n",
      "\n",
      "\n",
      "Epoch: 8 | Loss: 0.0000 | Val Accuracy: 60.67%\n",
      "\n",
      "\n",
      "Epoch: 9 | Loss: 0.0000 | Val Accuracy: 60.64%\n",
      "\n",
      "\n",
      "Epoch: 10 | Loss: 0.0000 | Val Accuracy: 60.64%\n",
      "\n",
      "\n",
      "Epoch: 11 | Loss: 0.0000 | Val Accuracy: 60.62%\n",
      "\n",
      "\n",
      "Epoch: 12 | Loss: 0.0000 | Val Accuracy: 60.64%\n",
      "\n",
      "\n",
      "Epoch: 13 | Loss: 0.0000 | Val Accuracy: 60.61%\n",
      "\n",
      "\n",
      "Epoch: 14 | Loss: 0.0000 | Val Accuracy: 60.64%\n",
      "\n",
      "\n",
      "Epoch: 15 | Loss: 0.0000 | Val Accuracy: 60.65%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(nn.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "loss_arr = []\n",
    "acc_arr = []\n",
    "min_loss = None\n",
    "min_acc = 0\n",
    "outputs = []\n",
    "early_stop = False\n",
    "early_stop_depth = 20\n",
    "encoder.eval()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    if early_stop:\n",
    "        if verbose != 0:\n",
    "            print(f'\\n\\n------EARLY STOP {min_loss}------\\n\\n')\n",
    "        break\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    nn.train()\n",
    "    nn.to(device)\n",
    "    for (image, label) in loader:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        x = encoder(image) # pretrained compressed image\n",
    "        \n",
    "        output = nn(x) # new model output\n",
    "    \n",
    "        loss = loss_function(output, goal.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # UI\n",
    "        if verbose == 2:\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.write(\"Epoch: {} [{:{}}] {:.1f}% | Loss: {}\".format(epoch+1, \"=\"*count, \n",
    "                                                                       len(loader)-1, \n",
    "                                                                       (100/(len(loader)-1)*count), \n",
    "                                                                       loss.item()))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "    loss_arr.append(loss.item())\n",
    "    \n",
    "    # Get the accuracy of the current state\n",
    "    nn.eval()\n",
    "    total_correct= 0\n",
    "    for (image_val, label_val) in val_loader:\n",
    "        image_val = image_val.to(device)\n",
    "        label_val = label_val.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            x2 = encoder(image_val)\n",
    "            o = nn._sigmoid(nn._feed_forward(x2))\n",
    "            val_outputs = torch.round(o)\n",
    "            total_samples += 1\n",
    "            \n",
    "            total_correct += (val_outputs == label_val).item()\n",
    "        \n",
    "    \n",
    "\n",
    "    accuracy = total_correct/len(val_loader)*100\n",
    "    if verbose != 0:\n",
    "        print(f'\\nEpoch: {epoch + 1} | Loss: {loss.item():.4f} | Val Accuracy: {accuracy:.2f}%', end='\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d2c5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nn.state_dict(), f'./ClassifierModels/class_model_gs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51c9b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a67a8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNet().to(device)\n",
    "nn.load_state_dict(torch.load('./ClassifierModels/class_model_gs.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b089a5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.24%\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device('cpu')\n",
    "ans = []\n",
    "total_samples = 0\n",
    "total_correct = 0\n",
    "nn.to(device)\n",
    "nn.eval()\n",
    "for (image, label) in test_loader:\n",
    "    nn.eval()\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoded = encoder(image)\n",
    "        not_rounded = nn._feed_forward(encoded)\n",
    "        \n",
    "        outputs = nn._sigmoid(not_rounded)\n",
    "        if outputs < 0.5: # 0.779\n",
    "            outputs = 0\n",
    "        else:\n",
    "            outputs = 1\n",
    "\n",
    "        total_samples += 1\n",
    "        total_correct += (outputs == label).item()\n",
    "        ans.append((label.item(), outputs))\n",
    "\n",
    "        \n",
    "print(f'Accuracy: {total_correct/len(test_loader)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0787ee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "total0, total1, correct0, correct1 = 0, 0, 0, 0\n",
    "for i in range(len(ans)):\n",
    "    if ans[i][0] == 0:\n",
    "        total0 += 1\n",
    "        if ans[i][1] == 0:\n",
    "            correct0 += 1\n",
    "    else:\n",
    "        total1 += 1\n",
    "        if ans[i][1] == 1:\n",
    "            correct1 += 1\n",
    "\n",
    "print(total0 + total1 == len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b99856df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 stats: total0=4284 | correct0=4110 | 95.94%\n",
      "1 stats: total1=2687 | correct1=159 | 5.92%\n",
      "Total stats: 61.24%\n",
      "Model guessed 0: 6638, getting 4110 correct\n",
      "Model guessed 1: 333, getting 159 correct\n"
     ]
    }
   ],
   "source": [
    "print(f'0 stats: {total0=} | {correct0=} | {100*(correct0/total0):.2f}%')\n",
    "print(f'1 stats: {total1=} | {correct1=} | {100*(correct1/total1):.2f}%')\n",
    "print(f'Total stats: {100*((correct0 + correct1)/(total0 + total1)):.2f}%')\n",
    "print(f'Model guessed 0: {correct0 + total1- correct1}, getting {correct0} correct')\n",
    "print(f'Model guessed 1: {correct1 + total0- correct0}, getting {correct1} correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d122816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into the 159 correct , cos distance for checking similarity between all 0's and 1's maybe 90%?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
