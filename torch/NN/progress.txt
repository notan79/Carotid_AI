AE=AE_CNN(
  (softmax): Softmax(dim=None)
  (encoder): Sequential(
    (0): Conv2d(3, 64, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(32, 45, kernel_size=(16, 16), stride=(4, 4), padding=(1, 1))
    (5): ReLU()
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=10125, out_features=10125, bias=True)
    (8): ReLU()
    (9): Linear(in_features=10125, out_features=8192, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=4096, out_features=8192, bias=True)
    (1): ReLU()
    (2): Linear(in_features=8192, out_features=10125, bias=True)
    (3): ReLU()
    (4): Unflatten(dim=1, unflattened_size=(45, 15, 15))
    (5): ConvTranspose2d(45, 32, kernel_size=(16, 16), stride=(4, 4), padding=(1, 1), output_padding=(1, 1))
    (6): ReLU()
    (7): ConvTranspose2d(32, 64, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (8): ReLU()
    (9): ConvTranspose2d(64, 3, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (10): Sigmoid()
  )
)

Training:

Epoch: 1 | Loss: 0.0631


Epoch: 2 | Loss: 0.0594


Epoch: 3 | Loss: 0.0594


Epoch: 4 | Loss: 0.0576


Epoch: 5 | Loss: 0.0602


Epoch: 6 | Loss: 0.0606


Epoch: 7 | Loss: 0.0552


Epoch: 8 | Loss: 0.0591


Epoch: 9 | Loss: 0.0577


Epoch: 10 | Loss: 0.0615


Epoch: 11 | Loss: 0.0583


Epoch: 12 | Loss: 0.0608


Epoch: 13 | Loss: 0.0624


Epoch: 14 | Loss: 0.0610


Epoch: 15 | Loss: 0.0573


Epoch: 16 | Loss: 0.0594


Epoch: 17 | Loss: 0.0569

Saved

