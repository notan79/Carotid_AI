AE=AE_CNN(
  (softmax): Softmax(dim=None)
  (encoder): Sequential(
    (0): Conv2d(3, 64, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 32, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))
    (3): ReLU()
    (4): Conv2d(32, 32, kernel_size=(16, 16), stride=(4, 4), padding=(1, 1))
    (5): ReLU()
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=7200, out_features=7200, bias=True)
    (8): ReLU()
    (9): Linear(in_features=7200, out_features=8192, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=4096, out_features=8192, bias=True)
    (1): ReLU()
    (2): Linear(in_features=8192, out_features=7200, bias=True)
    (3): ReLU()
    (4): Unflatten(dim=1, unflattened_size=(32, 15, 15))
    (5): ConvTranspose2d(32, 32, kernel_size=(16, 16), stride=(4, 4), padding=(1, 1), output_padding=(1, 1))
    (6): ReLU()
    (7): ConvTranspose2d(32, 64, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (8): ReLU()
    (9): ConvTranspose2d(64, 3, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (10): Sigmoid()
  )
)

Training:

Epoch: 1 | Loss: 0.0425


Epoch: 2 | Loss: 0.0382


Epoch: 3 | Loss: 0.0394


Epoch: 4 | Loss: 0.0376


Epoch: 5 | Loss: 0.0391


Epoch: 6 | Loss: 0.0391


Epoch: 7 | Loss: 0.0355


Epoch: 8 | Loss: 0.0387


Epoch: 9 | Loss: 0.0377


Epoch: 10 | Loss: 0.0400


Epoch: 11 | Loss: 0.0384


Epoch: 12 | Loss: 0.0400


Epoch: 13 | Loss: 0.0412


Epoch: 14 | Loss: 0.0405



------EARLY STOP 0.035452648997306824------

Saved

